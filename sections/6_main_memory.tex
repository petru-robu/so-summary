\section{Main Memory}

The CPU can directly access only \textbf{main memory} and \textbf{registers}. While register access occurs in one CPU clock cycle or less, main memory access can take many cycles, potentially causing a CPU \textbf{stall}. To bridge this speed gap, a \textbf{cache} is placed between the CPU and main memory.

\subsection{Memory Protection}

To ensure correct operation, we must protect the operating system from access by user processes and protect user processes from one another. This protection is provided by a pair of \textbf{base} and \textbf{limit registers}.

\begin{itemize}
    \item \textbf{Base register}: Holds the smallest legal physical memory address.
    \item \textbf{Limit register}: Specifies the size of the range (logical address space).
\end{itemize}

\includegraphics[scale=0.25]{9.5.png} % Figure 9.5: Base and Limit Registers

The hardware must check every memory access generated in user mode to ensure it is within the legal range: $base \leq address < base + limit$. If it is outside this range, the hardware traps to the OS with an illegal addressing error.

\includegraphics[scale=0.2]{9.6.png} % Figure 9.6: Hardware Address Protection

\subsection{Address Binding}

A user program goes through several steps before being executed. Addresses are represented in different ways: symbolic in source code, relocatable in compiled modules, and absolute after linking or loading .

\includegraphics[scale=0.3]{9.9.png} % Figure 9.9: Multistep Processing of a User Program

\subsection{Logical vs. Physical Address Space}

\begin{itemize}
    \item \textbf{Logical address}: Generated by the CPU; also referred to as a virtual address.
    \item \textbf{Physical address}: The actual address seen by the memory unit.
\end{itemize}

The \textbf{Memory-Management Unit (MMU)} is the hardware device that maps virtual addresses to physical addresses at run time.

\includegraphics[scale=0.2]{9.11.png} % Figure 9.11: Memory-Management Unit (MMU)

In a simple relocation-register scheme, the value in the \textbf{relocation register} (base) is added to every address generated by a user process. The user program never sees the real physical addresses.

\includegraphics[scale=0.2]{9.13.png} % Figure 9.13: Dynamic relocation using a relocation register

\subsection{Dynamic Loading and Linking}

\begin{itemize}
    \item \textbf{Dynamic Loading}: A routine is not loaded until it is called. This provides better memory-space utilization as unused routines are never loaded.
    \item \textbf{Dynamic Linking}: Linking is postponed until execution time. A small piece of code called a \textbf{stub} is used to locate the appropriate library routine.
\end{itemize}

\subsection{Contiguous Allocation}

In contiguous allocation, each process is contained in a single contiguous section of memory. Memory is usually partitioned into two: one for the resident OS and one for user processes.

\includegraphics[scale=0.2]{9.18.png} % Figure 9.18: Hardware Support for Relocation and Limit Registers

\subsubsection{Variable Partitioning}

The OS tracks which parts of memory are occupied and which are free (\textbf{holes}). When a process arrives, it is allocated a hole large enough to accommodate it.

\includegraphics[scale=0.25]{9.19.png} % Figure 9.19: Variable Partitioning

\subsubsection{Dynamic Storage-Allocation Problem}

To satisfy a request of size $n$, three common strategies are used:
\begin{itemize}
    \item \textbf{First-fit}: Allocate the first hole that is big enough.
    \item \textbf{Best-fit}: Allocate the smallest hole that is big enough (requires searching the whole list).
    \item \textbf{Worst-fit}: Allocate the largest hole.
\end{itemize}
First-fit and best-fit are generally better than worst-fit in speed and utilization. The \textbf{50-percent rule} suggests that for first-fit, $1/3$ of memory may be unusable due to fragmentation.

\subsubsection{Fragmentation}

\begin{itemize}
    \item \textbf{External Fragmentation}: Total memory exists for a request but is not contiguous. Can be reduced by \textbf{compaction}.
    \item \textbf{Internal Fragmentation}: Memory allocated to a process is slightly larger than requested; the difference is unused within the partition.
\end{itemize}

\section{Paging}

Paging allows the physical address space of a process to be noncontiguous, avoiding external fragmentation.

\begin{itemize}
    \item \textbf{Frames}: Fixed-sized blocks of physical memory.
    \item \textbf{Pages}: Blocks of the same size in logical memory.
    \item \textbf{Frame Table}: A data structure used to keep track of all free and occupied frames.
\end{itemize}

\subsection{Address Translation Scheme}

An address generated by the CPU is divided into:
\begin{itemize}
    \item \textbf{Page number (p)}: Used as an index into a \textbf{page table}.
    \item \textbf{Page offset (d)}: Combined with the base address from the page table to define the physical address.
\includegraphics[scale=0.2]{9.24.png} % Figure 9.25: Paging Hardware
\end{itemize}

\includegraphics[scale=0.2]{9.25.png} % Figure 9.25: Paging Hardware

\includegraphics[scale=0.2]{9.26.png} % Figure 9.26: Paging Model

In the paging example, logical memory is mapped to physical memory via the page table entries.

\includegraphics[scale=0.2]{9.27.png} % Figure 9.27: Paging Example

\subsection{Calculating Internal Fragmentation}

If the page size is 2,048 bytes and a process size is 72,766 bytes, it requires 35 full pages plus 1,086 bytes . The internal fragmentation is $2,048 - 1,086 = 962$ bytes.

\subsection{Free Frames}

The OS maintains a free-frame list to allocate memory to new processes.

\includegraphics[scale=0.2]{9.29.png} % Figure 9.29: Free Frames before and after allocation

\subsection{TLBs and Performance}

Every data access requires two memory accesses: one for the page table and one for the data. This is solved by using a \textbf{Translation Look-aside Buffer (TLB)}, a fast-lookup hardware cache.

\includegraphics[scale=0.2]{9.33.png} % Figure 9.33: Paging Hardware with TLB

\textbf{Effective Access Time (EAT)} calculation example:
If memory access is 10ns and hit ratio is 80\%:
$EAT = 0.80 \times 10 + 0.20 \times 20 = 12 \text{ ns}$ (20\% slowdown).
With 99\% hit ratio:
$EAT = 0.99 \times 10 + 0.01 \times 20 = 10.1 \text{ ns}$ (1\% slowdown).

\subsection{Shared Pages}

Read-only code (reentrant) can be shared among processes by mapping the same physical frames to different page tables.

\includegraphics[scale=0.25]{9.38.png} % Figure 9.38: Sharing of code in a paging environment

\section{Page Table Structures}

\subsection{Hierarchical Page Table}

For large address spaces, the page table itself is paged. A two-level scheme divides the logical address into an outer page index ($p_1$), an inner page displacement ($p_2$), and the page offset ($d$).

\includegraphics[scale=0.2]{9.40.png} % Figure 9.40: Hierarchical Page Table

\includegraphics[scale=0.2]{9.42.png} % Figure 9.42: Address-translation scheme

\subsection{Hashed Page Table}

Common for addresses > 32 bits. The virtual page number is hashed into a table containing a chain of elements that hash to the same location.

\includegraphics[scale=0.2]{9.46.png} % Figure 9.46: Hashed Page Table

\subsection{Inverted Page Table}

Rather than one table per process, there is one entry for each real frame of memory. Each entry includes the address and the \textbf{PID} of the owning process.

\includegraphics[scale=0.2]{9.48.png} % Figure 9.48: Inverted Page Table Architecture

\section{Swapping}

A process can be swapped out of memory to a \textbf{backing store} and later brought back. This allows the total physical memory space of processes to exceed actual physical memory.

\includegraphics[scale=0.25]{9.53.png} % Figure 9.53: Schematic View of Swapping

